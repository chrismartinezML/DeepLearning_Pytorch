{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TUTORIAL: ¡PYTORCH DESDE CERO!\n",
        "\n",
        "En este tutorial veremos paso a paso todos los elementos que usualmente hay que tener en cuenta para crear, entrenar, validar y poner a prueba prácticamente cualquier modelo de Deep Learning usando esta librería.\n",
        "\n",
        "\n",
        "Contenido:\n",
        "\n",
        "1. [Pre-requisitos](#scrollTo=WHDyLMetUr6e&line=9&uniqifier=1)\n",
        "2. [El problema a resolver](#scrollTo=-tudGJu8WZaD)\n",
        "3. [Los tensores](#scrollTo=0YbDrmdC_BQ3)\n",
        "4. [Los *Datasets* y el set de datos](#scrollTo=UtWKq4Es_bYc)\n",
        "5. [Cómo crear un modelo de *Deep Learning*](#scrollTo=w8lKSWreADfs&line=1&uniqifier=1)\n",
        "6. [Propagación hacia adelante y hacia atrás](#scrollTo=gLUg0KZMAdru&line=11&uniqifier=1)\n",
        "7. [Entrenando y validando un modelo: ejemplo completo](#scrollTo=HdQN4uq_Itu4&line=1&uniqifier=1)\n",
        "8. [Generando predicciones con el modelo entrenado](#scrollTo=iTwsL-8OP6ys&line=12&uniqifier=1)"
      ],
      "metadata": {
        "id": "TizDmrO0T1qV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pre-requisitos\n",
        "\n",
        "Para entender cómo usar Pytorch es necesario entender algunos conceptos básicos. Por tanto sugiero revisar estos videos en el canal de YouTube:\n",
        "\n",
        "- [¿Qué es una Red Neuronal?](https://youtu.be/53GUf747e38)\n",
        "- [¿Qué son los parámetros e hiper-parámetros de un modelo?](https://youtu.be/3Iu5m166rnE)\n",
        "- [¿Qué son los sets de entrenamiento, validación y prueba?](https://youtu.be/79K93XBOsIg)\n",
        "- [¿Qué es el algoritmo del Gradiente Descendente?](https://youtu.be/IKloEocn3Hw)\n",
        "- [¿Qué es la reproducibilidad en el Machine Learning?](https://youtu.be/tVD3PfYMk6g)\n",
        "- [¿Qué es el algoritmo de *back propagation*?](https://www.codificandobits.com/curso/fundamentos-deep-learning-python/redes-neuronales-15-entrenamiento-forward-back-propagation/)"
      ],
      "metadata": {
        "id": "WHDyLMetUr6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. El problema a resolver\n",
        "\n",
        "Supondremos un sencillo problema:\n",
        "\n",
        "> Crear una Red Neuronal para clasificar imágenes de dígitos escritos a mano\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1mckSBR3YFtRsblRcVfZ3--g4WR05_4sL)\n",
        "\n",
        "Así:\n",
        "\n",
        "- La entrada a la Red Neuronal serán imágenes en escala de gris, de tamaño 28x28, que contendrán un dígito (entre 0 y 9) escrito a mano\n",
        "- La Red Neuronal tendrá que aprender a clasificar estas imágenes en una de 10 posibles categorías (de 0 a 9).\n",
        "- Así que el dato predicho por la Red Neuronal será una cantidad numérica (entre 0 y 9) que debería coincidir con el dígito escrito en la imagen de entrada\n",
        "\n",
        "Pero antes de implementar la Red debemos entender la forma como Pytorch procesa los datos.\n",
        "\n",
        "Comencemos hablando de los Tensores."
      ],
      "metadata": {
        "id": "-tudGJu8WZaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Los tensores\n",
        "\n",
        "> Un tensor es simplemente un **arreglo de datos**\n",
        "\n",
        "Este arreglo puede ser un vector (1 dimensión), una matriz (2 dimensiones) o puede tener 3 o más dimensiones.\n",
        "\n",
        "Los tensores son usados por Pytorch para almacenar **todos los datos usados por el modelo de Deep Learning** (datos de entrada, parámetros, datos de salida).\n",
        "\n",
        "Comencemos creando de forma manual un simple Tensor con cantidades numéricas:\n",
        "\n"
      ],
      "metadata": {
        "id": "0YbDrmdC_BQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería\n",
        "import torch\n",
        "\n",
        "# Y crear un tensor de forma manual\n",
        "arreglo = [[2,3,4], [1,5,6]] # Arreglo 2D de 2 filas x 3 columnas\n",
        "tensor1 = torch.tensor(arreglo)\n",
        "print(tensor1)"
      ],
      "metadata": {
        "id": "Nh_G2eK2A-m5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a87795-83e7-4d66-80eb-e0373e16ce72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 3, 4],\n",
            "        [1, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una característica importante de los Tensores es que los podemos almacenar en la CPU (por defecto) o en la GPU (lo que permite aprovechar su velocidad de cómputo).\n",
        "\n",
        "Por ejemplo, veamos en qué dispositivo (*device*) está almacenado el tensor que acabamos de crear:"
      ],
      "metadata": {
        "id": "kRN46LNvZmpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1.device"
      ],
      "metadata": {
        "id": "VzkFa5RHBJCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db235e82-b588-4664-91e3-41df9d82e411"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si ahora nos conectamos a la GPU de Google Colab podemos almacenar esta información en una variable:"
      ],
      "metadata": {
        "id": "40Qs7V0gZ8u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectar la GPU\n",
        "device = (\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Usando {device}\")"
      ],
      "metadata": {
        "id": "85384ICyaKf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf0dbfa-fbe1-4b52-a77f-837766743b31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y podemos almacenar el tensor en la GPU usando el método \"to\":"
      ],
      "metadata": {
        "id": "BSX9Kw8VaP8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = tensor1.to(device)\n",
        "print(tensor1.device)"
      ],
      "metadata": {
        "id": "vrwzOl2tBgb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a831832-be6d-4d7a-a32d-aaa46a0db580"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto, si realizamos cualquier operación con este tensor ésta será realizada sobre la GPU (sobre esto volveremos en unos momentos).\n",
        "\n",
        "Y por ser un arreglo, un Tensor tiene atributos como por ejemplo su tamaño (`shape`):"
      ],
      "metadata": {
        "id": "KxiYPA0faXbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1.shape"
      ],
      "metadata": {
        "id": "7XkLz1KLBeTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a39d7a6-bd47-44bd-fac1-2322797c3cc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y podemos acceder al listado completo de atributos usando `tensor1.` + <kbd>⇥ Tab</kbd>:"
      ],
      "metadata": {
        "id": "oj_mknGRaq1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1"
      ],
      "metadata": {
        "id": "iPED1CXuargQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1330b7-1d9e-4157-a403-6826b0e75804"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3, 4],\n",
              "        [1, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usualmente no es necesario trabajar directamente con los tensores así que de momento es suficiente con que entendamos qué son y para qué se usan.\n",
        "\n",
        "Veamos ahora los *Datasets* y el set de datos que usaremos en este tutorial."
      ],
      "metadata": {
        "id": "N_NAce9WbOK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Los *Datasets* y el set de datos\n",
        "\n",
        "En Pytorch existen dos módulos que nos permiten cargar sets de datos:\n",
        "\n",
        "- `torch.utils.data.Dataset`: nos permite cargar datasets que se encuentran en la base de datos de Pytorch\n",
        "- `torch.utils.data.DataLoader`: nos permite cargar datasets propios así como **iterar** sobre un `Dataset`.\n",
        "\n",
        "En este tutorial usaremos estos dos métodos:\n",
        "\n",
        "1. Primero usaremos `torchvision.datasets` para cargar el set de datos de imágenes de caracteres\n",
        "2. Más adelante usaremos `torch.utils.data.DataLoader` para iterar sobre el set de datos de imágenes y así entrenar y validar el modelo\n",
        "\n",
        "Comencemos usando `torchvision.datasets` para cargar un set de datos pre-existente.\n",
        "\n",
        "### 4.1. Descargar el set de datos\n",
        "\n",
        "Usaremos el set de datos MNIST, el cual contiene un total de 60.000 imágenes cada una con un dígito (entre 0 y 9) escrito a mano. Además, por cada imagen se tiene su categoría correspondiente (una cantidad numérica entre 0 y 9).\n",
        "\n",
        "Comencemos descargando este set de datos desde la base de datos de Pytorch:\n"
      ],
      "metadata": {
        "id": "UtWKq4Es_bYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías requeridas\n",
        "from torchvision import datasets # Para descargar el dataset\n",
        "from torchvision.transforms import ToTensor # Para convertir los datos a Tensores\n",
        "import matplotlib.pyplot as plt # Para graficar las imágenes + categorías\n",
        "\n",
        "# Crear el directorio \"datos\" y ejecutar el siguiente código:\n",
        "data_mnist = datasets.MNIST(\n",
        "    root = \"datos\", # Carpeta donde se almacenará\n",
        "    train=True, # True: 60.000 imágenes, False: 10.000 imágenes\n",
        "    download=True,\n",
        "    transform=ToTensor() # Convertir imágenes a tensores\n",
        ")"
      ],
      "metadata": {
        "id": "zExZ2ns7czzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5c34b8-6b01-4dc7-b594-1ea6b514f578"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to datos/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.17MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datos/MNIST/raw/train-images-idx3-ubyte.gz to datos/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to datos/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 151kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datos/MNIST/raw/train-labels-idx1-ubyte.gz to datos/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to datos/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.44MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datos/MNIST/raw/t10k-images-idx3-ubyte.gz to datos/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to datos/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.32MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datos/MNIST/raw/t10k-labels-idx1-ubyte.gz to datos/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ejecutar la anterior celda se creará la carpeta \"datos\" en el disco remoto de Google Colab y allí se almacenará la totalidad del set de datos.\n",
        "\n",
        "Veamos algunas características del set de datos que acabamos de descargar:"
      ],
      "metadata": {
        "id": "_32H0oG-dOGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mnist"
      ],
      "metadata": {
        "id": "K3_02WEHDvHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a71c94-30fd-410f-da0a-fb13d63a50ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: datos\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que tiene un total de 60.000 imágenes y que en últimas es una variable de tipo \"Dataset\".\n",
        "\n",
        "Grafiquemos algunas imágenes de ejemplo para entender las características del set de datos:"
      ],
      "metadata": {
        "id": "fk2qn9_AdbWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "fils, cols = 3, 3\n",
        "\n",
        "for i in range(1, cols * fils + 1):\n",
        "    # Escoger una imagen aleatoria\n",
        "    sample_idx = torch.randint(len(data_mnist), size=(1,)).item()\n",
        "\n",
        "    # Extraer imagen y categoría\n",
        "    img, label = data_mnist[sample_idx]\n",
        "\n",
        "    # Dibujar\n",
        "    figure.add_subplot(fils, cols, i)\n",
        "    plt.title(str(label)) # Categoría\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\") # Imagen\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rmMGCxhDEQyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "b269ca1d-d485-4a9f-8675-e10aafd439be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimamos en pantalla algunas características de una de estas imágenes y de su categoría:"
      ],
      "metadata": {
        "id": "NEw9KpABeFPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Características de una imagen\n",
        "print(f'Tipo de dato imagen: {type(img)}')\n",
        "print(f'Tamaño imagen: {img.shape}')\n",
        "print(f'Mínimo y máximo imagen: {img.min()}, {img.max()}')\n",
        "print(f'Tipo de dato categoría: {type(label)}')"
      ],
      "metadata": {
        "id": "nh1SczeEEosO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcad2136-94e1-4580-9282-a6eb1f805764"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dato imagen: <class 'torch.Tensor'>\n",
            "Tamaño imagen: torch.Size([1, 28, 28])\n",
            "Mínimo y máximo imagen: 0.0, 1.0\n",
            "Tipo de dato categoría: <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada imagen tiene estas características:\n",
        "\n",
        "- Es un Tensor\n",
        "- Tiene un tamaño de 1x28x28 (el 1 indica que es una imagen en escala de grises)\n",
        "- Sus pixeles tienen valores entre 0 y 1\n",
        "\n",
        "Por otra parte es importante tener en cuenta que la categoría está por defecto almacenada como un entero (*int*) y no como un tensor. Esto implica que más adelante **tendremos que convertir la categoría de cada imagen a un tensor para que pueda ser procesada por la Red Neuronal.**"
      ],
      "metadata": {
        "id": "PGQoAhWGeU-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Sets de entrenamiento, validación y prueba\n",
        "\n",
        "Siempre que construimos un modelo de Deep Learning debemos realizar la partición del set de datos en entrenamiento, validación y prueba.\n",
        "\n",
        "En este caso haremos la partición usando proporciones del 80, 10 y 10% respectivamente.\n",
        "\n",
        "Esto lo podemos lograr fácilmente usando el método `random_split` de Pytorch.\n",
        "\n",
        "Para ello, primero fijamos la semilla del generador de números aleatorio de Pytorch, lo que garantizará que cada vez que ejecutemos el código obtendremos las mismas particiones:"
      ],
      "metadata": {
        "id": "AUdKYh0gevik"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YNvIedZnh1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "id": "lYYGy3fffK0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893ba20b-93a6-4200-ab60-6e78e0e5f0e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7db2352d89f0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y ahora sí usamos `random_split` para generar las particiones con las proporciones deseadas (80, 10 y 10%):"
      ],
      "metadata": {
        "id": "9YcovfBzfM_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val, test = torch.utils.data.random_split(\n",
        "    data_mnist, [0.8, 0.1, 0.1]\n",
        ")\n",
        "\n",
        "# Verificar tamaños\n",
        "print(f'Tamaño set de entrenamiento: {len(train)}')\n",
        "print(f'Tamaño set de validación: {len(val)}')\n",
        "print(f'Tamaño set de prueba: {len(test)}')\n",
        "\n",
        "# Y verificar el tipo de dato de train, val y test\n",
        "print(f'Tipo de dato set \"train\": {type(train)}')\n",
        "print(f'Tipo de dato set \"val\": {type(val)}')\n",
        "print(f'Tipo de dato set \"test\": {type(test)}')"
      ],
      "metadata": {
        "id": "52CUpU_UE2si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d1a8c0-3e41-45db-dab0-1bfe530146a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño set de entrenamiento: 48000\n",
            "Tamaño set de validación: 6000\n",
            "Tamaño set de prueba: 6000\n",
            "Tipo de dato set \"train\": <class 'torch.utils.data.dataset.Subset'>\n",
            "Tipo de dato set \"val\": <class 'torch.utils.data.dataset.Subset'>\n",
            "Tipo de dato set \"test\": <class 'torch.utils.data.dataset.Subset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y vemos que los tres subsets de datos son de tipo `dataset`.\n",
        "\n",
        "Ya estamos listos para ver cómo crear el modelo (la Red Neuronal)."
      ],
      "metadata": {
        "id": "Hhg10GF6x_sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ¿Cómo crear un modelo de *Deep Learning*?\n",
        "\n",
        "Crearemos una sencilla Red Neuronal con estas características:\n",
        "\n",
        "- Capa de entrada: 28x28 = 784 elementos\n",
        "- Capa oculta: 15 neuronas, activación ReLU\n",
        "- Capa de salida: 10 neuronas (1 por cada categoría a predecir), activación *softmax*\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1md-A_Qc1cbBKnWVTfUm4qv2egv1bwX_o)\n",
        "\n",
        "Adicionalmente, antes de llevar cada imagen a la Red tendremos que **aplanarla** para convertirla de un tensor 3D de 1x28x28 a un tensor de 1D de 28x28 = 784 (el mismo tamaño de la capa de entrada de la Red):\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1md2CPT14WYV2K6bJppamDsi_-6pUpLxH)\n",
        "\n",
        "Para crear la Red Neuronal debemos **crear una sub-clase de `nn.Module`**. Veamos cómo hacerlo:"
      ],
      "metadata": {
        "id": "w8lKSWreADfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar módulo nn\n",
        "from torch import nn\n",
        "\n",
        "# Crear la Red Neuronal como una subclase de nn.Module\n",
        "# Siempre se añaden dos métodos a esta subclase\n",
        "# 1. Método \"init\": define la arquitectura de la red\n",
        "# 2. Método \"forward\": define cómo será generada cada predicción\n",
        "\n",
        "class RedNeuronal(nn.Module):\n",
        "    # 1. Método \"init\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Y agregar secuencialmente las capas\n",
        "        self.aplanar = nn.Flatten() # Aplanar imágenes de entrada\n",
        "        self.red = nn.Sequential(\n",
        "            nn.Linear(28*28, 15), # Capa de entrada + capa oculta\n",
        "            nn.ReLU(), # Función de activación capa oculta\n",
        "            nn.Linear(15,10), # Capa de salida SIN activación\n",
        "        )\n",
        "\n",
        "    # 2. Método \"forward\" (x = dato de entrada)\n",
        "    def forward(self, x):\n",
        "        # Definir secuencialmente las operaciones a aplicar\n",
        "        x = self.aplanar(x) # Aplanar dato\n",
        "        logits = self.red(x) # Generar predicción\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "QgKlVKSo1Q3e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Nota: a pesar de que la capa de salida debería tener una activación *softmax* esta no se incluye porque no es necesaria para el entrenamiento (sólo es necesaria para garantizar que las salidas de cada neurona de salida suman exactamente 1).\n",
        "\n",
        "Habiendo creado la clase ya podemos crear la Red Neuronal simplemente:\n",
        "\n",
        "1. Creando una instancia de la clase `RedNeuronal`\n",
        "2. Y moviendo esta instancia a la GPU"
      ],
      "metadata": {
        "id": "wr4Jfff_4L_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = RedNeuronal().to(device)\n",
        "print(modelo)"
      ],
      "metadata": {
        "id": "sgyjy11kAEjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec53b81-32e0-4ca0-c621-d5016067de09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RedNeuronal(\n",
            "  (aplanar): Flatten(start_dim=1, end_dim=-1)\n",
            "  (red): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=15, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=15, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos usar el método `parameters()` para imprimir en pantalla el número de parámetros a entrenar en este modelo:"
      ],
      "metadata": {
        "id": "1gvcl1rH5Gra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in modelo.parameters())\n",
        "print(\"Número de parámetros a entrenar: \", total_params)"
      ],
      "metadata": {
        "id": "5iA8jYQtAQDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130bc69a-e64e-410d-85d9-d839f95de739"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de parámetros a entrenar:  11935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Propagación hacia adelante y hacia atrás\n",
        "\n",
        "La propagación hacia adelante y hacia atrás son las dos fases clave al momento de entrenar la Red Neuronal.\n",
        "\n",
        "Veamos cada fase en detalle:\n",
        "\n",
        "### 6.1. Propagación hacia adelante (*forward propagation*)\n",
        "\n",
        "Con la propagación hacia adelante se toma el dato de entrada ($X$), la Red lo procesa y genera una predicción ($y_{pred}$ ):\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1meBLFk2SO5uOhWms2pQ4QdzWgGgOaT8q)\n",
        "\n",
        "Veamos cómo realizar la propagación hacia adelante:"
      ],
      "metadata": {
        "id": "gLUg0KZMAdru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer una imagen y su categoría del set de entrenamiento\n",
        "img, lbl = train[200]\n",
        "\n",
        "print(type(img))\n",
        "print(type(lbl))"
      ],
      "metadata": {
        "id": "pi86fqdC7EGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e911d26-4c85-43b1-ef07-86c265a88cac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la imagen es un Tensor mientras que la categoría es un entero. Debemos convertir esta categoría a un tensor para poder presentarla al modelo:"
      ],
      "metadata": {
        "id": "u3UTnVV87XWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir \"lbl\" a Tensor usando \"tensor\", definir tamaño igual a 1 (1 dato)\n",
        "# con \"reshape\"\n",
        "lbl = torch.tensor(lbl).reshape(1)\n",
        "print(type(lbl))"
      ],
      "metadata": {
        "id": "Pu4U2mNz7dTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78352b67-160e-4763-bc7e-de3b93e2f8b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora llevamos tanto el dato como su categoría a la GPU:"
      ],
      "metadata": {
        "id": "BRQLcoPJ8k8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, lbl = img.to(device), lbl.to(device)"
      ],
      "metadata": {
        "id": "w-bqC9Ez8qVv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y ahora sí propagamos el dato hacia adelante:"
      ],
      "metadata": {
        "id": "7HX2Pl_kCQcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = modelo(img)\n",
        "print(logits)"
      ],
      "metadata": {
        "id": "fJw1Kj7eCTt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c02573c-6494-4cc5-b020-27f0ed914b33"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1762, -0.0300,  0.1198, -0.0336, -0.0994,  0.0021, -0.1259,  0.0016,\n",
            "          0.0412,  0.1990]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La predicción (o *logits*) es un arreglo **no normalizado** de 10 valores numéricos (puesto que tenemos 10 categorías).\n",
        "\n",
        "No normalizado implica que su suma no es igual a 1. Para normalizarlo se puede usar la función *softmax* aunque no es necesario, podemos calcular la categoría predicha simplemente encontrando la posición donde se encuentre el valor máximo:"
      ],
      "metadata": {
        "id": "nvXN8LiyCbWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categoría predicha\n",
        "y_pred = logits.argmax(1)\n",
        "\n",
        "# Mostremos la imagen original\n",
        "plt.imshow(img.cpu().squeeze(), cmap=\"gray\");\n",
        "\n",
        "# Y comparemos la categoría predicha con la categoría real\n",
        "print(f'Logits: {logits}')\n",
        "print(f'Categoría predicha: {y_pred[0]}')\n",
        "print(f'Categoría real: {lbl[0]}')"
      ],
      "metadata": {
        "id": "aCo1g4nhC5q8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "884b393a-b06e-4bf9-fdb9-06db005d2911"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[ 0.1762, -0.0300,  0.1198, -0.0336, -0.0994,  0.0021, -0.1259,  0.0016,\n",
            "          0.0412,  0.1990]], grad_fn=<AddmmBackward0>)\n",
            "Categoría predicha: 9\n",
            "Categoría real: 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Es de esperar que la categoría predicha (0) no coincida con la categoría real (6) puesto que no hemos entrenado la Red Neuronal!\n",
        "\n",
        "Veamos ahora la segunda fase que hace parte del entrenamiento: la propagación hacia atrás."
      ],
      "metadata": {
        "id": "U2HUJF2eD4gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Propagación hacia atrás (*backward propagation* o *backprop*)\n",
        "\n",
        "Esta propagación hacia atrás permite **actualizar los parámetros del modelo con base en el gradiente de la pérdida**.\n",
        "\n",
        "La idea básica es **ajustar estos parámetros para minimizar la pérdida** (mejorando así las predicciones).\n",
        "\n",
        "Los pasos involucrados en esta propagación hacia atrás son:\n",
        "\n",
        "0. Definir la **pérdida** (función que se usará para comparar las predicciones con las categorías reales) y el **optimizador** (algoritmo que se usará para ajustar los parámetros y minimizar la pérdida)\n",
        "1. Tomar cada predicción (*logits*), compararla con la categoría real correspondiente ($y$) y calcular la **pérdida** ($loss$)\n",
        "2. Calcular los **gradientes** de la pérdida (derivadas con respecto a cada parámetro)\n",
        "3. Actualizar los parámetros del modelo usando los gradientes y un algoritmo de optimización (como por ejemplo el Gradiente Descendente):\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1meRc9wEIKcSzj2X3lR7DgTgoIs5ixqHJ)\n",
        "\n",
        "Veamos cómo implementar cada uno de estos pasos.\n",
        "\n",
        "Comencemos definiendo la función de pérdida (entropía cruzada) y el optimizador a usar (Gradiente Descendente). En este último caso usaremos una tasa de aprendizaje de 0.2:"
      ],
      "metadata": {
        "id": "S57KJRyNEEMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Pérdida y optimizador\n",
        "fn_perdida = nn.CrossEntropyLoss()\n",
        "optimizador = torch.optim.SGD(modelo.parameters(), lr=0.2) # se ponen acá los parámetros para que se actualícen"
      ],
      "metadata": {
        "id": "fcX0dCdcCPtR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que al definir el optimizador el primer argumento son los parámetros del modelo (`modelo.parameters()`).\n",
        "\n",
        "Esto permite \"conectar\" el modelo al optimizador de tal manera que durante el entrenamiento el optimizador pueda ajustar los parámetros para mejorar las predicciones.\n",
        "\n",
        "Ahora tomamos la predicción (que se obtuvo con la propagación hacia adelante), la comparamos con la categoría real y calculamos la pérdida. La\n",
        "\n",
        "\n",
        "Esto se hace con una sola línea de código:"
      ],
      "metadata": {
        "id": "vHr-UQ0IFE54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calcular pérdida\n",
        "loss = fn_perdida(logits, lbl)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "LRpf3jl-Fi5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06523221-b8ea-4ab7-8590-f52939e8f8bd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4591, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora calculamos los gradientes de la pérdida. Esto logra usando el método `backward()` asociado a la variable `loss`:\n"
      ],
      "metadata": {
        "id": "I-tedsIYGSLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Calcular los gradientes de la pérdida\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "LTq4dcjBGm12"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y finalmente actualizamos los parámetros del modelo usando el optimizador.\n",
        "\n",
        "Esto se logra en dos pasos:\n",
        "\n",
        "1. Usando el método `step()` que actualiza los parámetros del modelo\n",
        "2. Usando el método `zero_grad()` para explícitamente borrar los gradientes calculados anteriormente (pues Pytorch los deja almacenados y esto afecta el entrenamiento).\n",
        "\n",
        "Estos dos pasos los podemos implementar en dos líneas de código:"
      ],
      "metadata": {
        "id": "2n3lAL8tG2B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Actualizar los parámetros del modelo\n",
        "optimizador.step()\n",
        "optimizador.zero_grad()"
      ],
      "metadata": {
        "id": "k3sv4nznHCJq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y listo, ya tenemos la propagación hacia atrás.\n",
        "\n",
        "Así que para resumir, re-escribamos todas las líneas de código anteriores para combinar en un sólo bloque la propagación hacia adelante y hacia atrás:"
      ],
      "metadata": {
        "id": "IwQVRzSNHvKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# img: dato, lbl: categoría real\n",
        "\n",
        "# Propagación hacia adelante (generar predicciones)\n",
        "logits = modelo(img)\n",
        "\n",
        "# Propagación hacia atrás\n",
        "loss = fn_perdida(logits, lbl) # Perdida\n",
        "loss.backward() # Calcular gradientes\n",
        "optimizador.step() # Actualizar parámetros del modelo\n",
        "optimizador.zero_grad() # Borrar gradientes calculados anteriormente"
      ],
      "metadata": {
        "id": "JS-fSvXKH5od"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y listo, tenemos en muy pocas líneas de código los dos pasos esenciales en el entrenamiento de cualquier modelo de Deep Learning: *forward* + *back* *propagation*.\n",
        "\n",
        "Al entrenar el modelo no usaremos una sola imagen sino que usaremos todo el set de entrenamiento. Y además repetiremos la anterior celda de código varias veces (el número de iteraciones de entrenamiento que definamos).\n",
        "\n",
        "Así que con todo lo visto hasta este punto ya estamos listos para conectar todos estos elementos y ver cómo se crea, entrena y valida nuestra Red Neuronal para clasificar imágenes."
      ],
      "metadata": {
        "id": "p7LU5hcnIWWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Entrenando y validando un modelo: ejemplo completo\n",
        "\n",
        "En esta última parte simplemente tomaremos las porciones de código de las secciones anteriores y las organizaremos para entender la lógica de creación, entrenamiento y validación de la Red Neuronal.\n",
        "\n",
        "Veamos todo esto en detalle."
      ],
      "metadata": {
        "id": "HdQN4uq_Itu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1. Creación de la Red Neuronal\n",
        "\n",
        "Escribamos en una sola celda el código necesario para crear la clase y la instancia correspondiente a nuestro modelo:"
      ],
      "metadata": {
        "id": "CHKMeCURJFVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase\n",
        "class RedNeuronal(nn.Module):\n",
        "    # 1. Método \"init\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Y agregar secuencialmente las capas\n",
        "        self.aplanar = nn.Flatten() # Aplanar imágenes de entrada\n",
        "        self.red = nn.Sequential(\n",
        "            nn.Linear(28*28, 15), # Capa de entrada + capa oculta\n",
        "            nn.ReLU(), # Función de activación capa oculta\n",
        "            nn.Linear(15,10), # Capa de salida SIN activación\n",
        "        )\n",
        "\n",
        "    # 2. Método \"forward\" (x = dato de entrada)\n",
        "    def forward(self, x):\n",
        "        # Definir secuencialmente las operaciones a aplicar\n",
        "        x = self.aplanar(x) # Aplanar dato\n",
        "        logits = self.red(x) # Generar predicción\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Instancia (llevada a la GPU)\n",
        "modelo = RedNeuronal().to(device)"
      ],
      "metadata": {
        "id": "NrYzQfBwJOBC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de entrenar la Red (usando el código para la propagación hacia adelante y hacia atrás), debemos preparar nuestros set de entrenamiento y validación. Veamos cómo hacer esto."
      ],
      "metadata": {
        "id": "4Esjub4jJZJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2. Preparar los sets de entrenamiento y validación\n",
        "\n",
        "El set de entrenamiento nos permitirá usar la propagación hacia adelante y hacia atrás para automáticamente actualizar los parámetros del modelo.\n",
        "\n",
        "Por su parte el set de validación se usará para que tras cada iteración de entrenamiento, pongamos a prueba el modelo y verifiquemos su desempeño.\n",
        "\n",
        "Como tenemos muchos datos de entrenamiento (48.000) y muchos de validación (6.000) no podemos presentarlos en bloque al modelo pues habría problemas con la memoria RAM.\n",
        "\n",
        "En lugar de ello los presentamos **por lotes** (*batches*), es decir pequeños grupos de datos.\n",
        "\n",
        "Para poder crear estos lotes y presentarlos al modelo usamos `DataLoader`el segundo módulo de procesamiento de datos que posee Pytorch:"
      ],
      "metadata": {
        "id": "l9vTtmibJhgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Definir el tamaño del lote\n",
        "TAM_LOTE = 1000 # batch size\n",
        "\n",
        "# Crear los \"dataloaders\" para los sets de entrenamiento y validación\n",
        "train_loader = DataLoader(\n",
        "    dataset=train,\n",
        "    batch_size=TAM_LOTE,\n",
        "    shuffle=True # Mezclar los datos aleatoriamente al crear cada lote\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val,\n",
        "    batch_size=TAM_LOTE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "YyTtsBboKg3T"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando entrenemos y validemos el modelo le presentaremos, en cada iteración, las variables `train_loader` y `val_loader` para que se realice el entrenamiento y la validación.\n",
        "\n",
        "Así que ya tenemos todo listo para realizar este entrenamiento y validación de la red. Veamos el código."
      ],
      "metadata": {
        "id": "swGPKj9MKy4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3. Entrenamiento y validación del modelo\n",
        "\n",
        "Comencemos definiendo los hiper-parámetros: la tasa de aprendizaje del algoritmo de optimización y el número de iteraciones de entrenamiento:"
      ],
      "metadata": {
        "id": "vfbmwRBgLDsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "TASA_APRENDIZAJE = 0.1 # learning rate (0.1)\n",
        "EPOCHS = 10 # Número de iteraciones de entrenamiento"
      ],
      "metadata": {
        "id": "9VbCfHq4HRYa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora definimos la función de pérdida (*entropía cruzada*) y el optimizador (Gradiente Descendente). Este optimizador tendrá la tasa de aprendizaje definida en la celda anterior:"
      ],
      "metadata": {
        "id": "N2lFqGaNLSQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de pérdida y optimizador\n",
        "fn_perdida = nn.CrossEntropyLoss()\n",
        "optimizador = torch.optim.SGD(modelo.parameters(), lr=TASA_APRENDIZAJE)"
      ],
      "metadata": {
        "id": "ExWwmztiADDV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora crearemos la función `train_loop` que se ejecutará en cada iteración del entrenamiento.\n",
        "\n",
        "Esta función usa las dos fases vistas anteriormente: propagación hacia adelante y hacia atrás.\n",
        "\n",
        "Además, en cada iteración calcularemos dos variables que nos permitirán monitorear el progreso del entrenamiento:\n",
        "\n",
        "- `perdida_train`: valores promedio de la función de pérdida en cada iteración\n",
        "- `exactitud`: valores promedio (en cada iteración) de la exactitud del modelo al momento de clasificar los datos. La exactitud es simplemente el porcentaje de datos clasificados correctamente con respecto al total de datos clasificados.\n",
        "\n",
        "Veamos cómo implementar esta función:"
      ],
      "metadata": {
        "id": "bCWsMYOHLgHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Myv9c7ht-wc6"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    # Cantidad de datos de entrenamiento y cantidad de lotes\n",
        "    train_size = len(dataloader.dataset)\n",
        "    nlotes = len(dataloader)\n",
        "\n",
        "    # Indicarle a Pytorch que entrenaremos el modelo\n",
        "    model.train()\n",
        "\n",
        "    # Inicializar acumuladores pérdida y exactitud\n",
        "    perdida_train, exactitud = 0, 0\n",
        "\n",
        "    # Presentar los datos al modelo por lotes (de tamaño TAM_LOTE)\n",
        "    for nlote, (X, y) in enumerate(dataloader):\n",
        "        # Mover \"X\" y \"y\" a la GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Forward propagation\n",
        "        logits = model(X)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss = loss_fn(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Acumular valores de pérdida y exactitud\n",
        "        # perdida_train <- perdida_train + perdida_actual\n",
        "        # exactitud <- exactitud + numero_aciertos_actuales\n",
        "        perdida_train += loss.item()\n",
        "        exactitud += (logits.argmax(1)==y).type(torch.float).sum().item()\n",
        "\n",
        "        # Imprimir en pantalla la evolución del entrenamiento (cada 10 lotes)\n",
        "        if nlote % 10 == 0:\n",
        "            # Obtener el valor de la pérdida (loss) y el número de datos procesados (ndatos)\n",
        "            ndatos = nlote*TAM_LOTE\n",
        "\n",
        "            # E imprimir en pantalla\n",
        "            print(f\"\\tPérdida: {loss.item():>7f}  [{ndatos:>5d}/{train_size:>5d}]\")\n",
        "\n",
        "    # Al terminar de presentar todos los datos al modelo, promediar pérdida y exactitud\n",
        "    perdida_train /= nlotes # Pérdida promedio = pérdida acumulada / número de lotes\n",
        "    exactitud /= train_size # Exactitud promedio = exactitud acumulada / número de datos\n",
        "\n",
        "    # E imprimir información\n",
        "    print(f'\\tExactitud/pérdida promedio:')\n",
        "    print(f'\\t\\tEntrenamiento: {(100*exactitud):>0.1f}% / {perdida_train:>8f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muy bien, ya tenemos la función `train_loop` que permite ejecutar una iteración de entrenamiento del modelo. En un momento la usaremos.\n",
        "\n",
        "La idea es que en cada iteración, además de entrenar el modelo, lo validemos. La validación consiste simplemente en:\n",
        "\n",
        "1. Tomar el modelo entrenado y generar predicciones **con el set de validación**\n",
        "2. Con las predicciones generadas en (1) calcular la pérdida y la exactitud del modelo\n",
        "\n",
        "Para lograr esto crearemos una segunda función que llamaremos `val_loop`. Esta función es similar a la anterior con las siguientes diferencias:\n",
        "\n",
        "- No presentaremos a la entrada de esta función el optimizador, pues no realizaremos entrenamiento\n",
        "- No ejecutaremos propagación hacia atrás, pues no realizaremos entrenamiento\n",
        "- Sólo realizaremos la propagación hacia adelante para generar las predicciones\n",
        "\n",
        "En este último caso usamos `no_grad()` para indicarle de forma explícita a Pytorch que NO calcularemos gradientes (puesto que no estamos entrenando el modelo). Esto simplifica los cálculos y agiliza la ejecución del código de validación.\n",
        "\n",
        "Veamos entonces cómo implementar `val_loop`:"
      ],
      "metadata": {
        "id": "ue9FbYSHNLP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def val_loop(dataloader, model, loss_fn):\n",
        "    # Cantidad de datos de validación y cantidad de lotes\n",
        "    val_size = len(dataloader.dataset)\n",
        "    nlotes = len(dataloader)\n",
        "\n",
        "    # Indicarle a Pytorch que validaremos el modelo\n",
        "    model.eval()\n",
        "\n",
        "    # Inicializar acumuladores pérdida y exactitud\n",
        "    perdida_val, exactitud = 0, 0\n",
        "\n",
        "    # Evaluar (generar predicciones) usando \"no_grad\"\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # Mover \"X\" y \"y\" a la GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Propagación hacia adelante (predicciones)\n",
        "            logits = model(X)\n",
        "\n",
        "            # Acumular valores de pérdida y exactitud\n",
        "            perdida_val += loss_fn(logits, y).item()\n",
        "            exactitud += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    # Tras generar las predicciones calcular promedios de pérdida y exactitud\n",
        "    perdida_val /= nlotes\n",
        "    exactitud /= val_size\n",
        "\n",
        "    # E imprimir en pantalla\n",
        "    print(f\"\\t\\tValidación: {(100*exactitud):>0.1f}% / {perdida_val:>8f} \\n\")"
      ],
      "metadata": {
        "id": "F2wFBPpmNl3W"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Y listo! Ya tenemos todo lo necesario para entrenar y validar nuestro modelo de Deep Learning.\n",
        "\n",
        "Sólo nos restan unas cuantas líneas de código en las cuales de forma iterativa llamaremos las dos funciones que acabamos de crear (`train_loop` y `val_loop`):"
      ],
      "metadata": {
        "id": "-omMez6IO_6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(EPOCHS):\n",
        "    print(f\"Iteración {t+1}/{EPOCHS}\\n-------------------------------\")\n",
        "    # Entrenar\n",
        "    train_loop(train_loader, modelo, fn_perdida, optimizador)\n",
        "    # Validar\n",
        "    val_loop(val_loader, modelo, fn_perdida)\n",
        "print(\"Listo, el modelo ha sido entrenado!\")"
      ],
      "metadata": {
        "id": "4hGKOAjJNYq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9bdf89-f6f6-43d4-dc67-1790ae2a2377"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración 1/10\n",
            "-------------------------------\n",
            "\tPérdida: 2.306079  [    0/48000]\n",
            "\tPérdida: 2.152023  [10000/48000]\n",
            "\tPérdida: 1.934167  [20000/48000]\n",
            "\tPérdida: 1.698753  [30000/48000]\n",
            "\tPérdida: 1.459207  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 55.3% / 1.835414\n",
            "\t\tValidación: 71.7% / 1.283330 \n",
            "\n",
            "Iteración 2/10\n",
            "-------------------------------\n",
            "\tPérdida: 1.239127  [    0/48000]\n",
            "\tPérdida: 1.107620  [10000/48000]\n",
            "\tPérdida: 0.918477  [20000/48000]\n",
            "\tPérdida: 0.834119  [30000/48000]\n",
            "\tPérdida: 0.806360  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 77.3% / 0.934018\n",
            "\t\tValidación: 80.6% / 0.722597 \n",
            "\n",
            "Iteración 3/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.747941  [    0/48000]\n",
            "\tPérdida: 0.619071  [10000/48000]\n",
            "\tPérdida: 0.619623  [20000/48000]\n",
            "\tPérdida: 0.557980  [30000/48000]\n",
            "\tPérdida: 0.580324  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 84.8% / 0.605026\n",
            "\t\tValidación: 85.9% / 0.546174 \n",
            "\n",
            "Iteración 4/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.560375  [    0/48000]\n",
            "\tPérdida: 0.513927  [10000/48000]\n",
            "\tPérdida: 0.517033  [20000/48000]\n",
            "\tPérdida: 0.488448  [30000/48000]\n",
            "\tPérdida: 0.495452  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 87.3% / 0.486735\n",
            "\t\tValidación: 87.4% / 0.468979 \n",
            "\n",
            "Iteración 5/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.430331  [    0/48000]\n",
            "\tPérdida: 0.461910  [10000/48000]\n",
            "\tPérdida: 0.411848  [20000/48000]\n",
            "\tPérdida: 0.391283  [30000/48000]\n",
            "\tPérdida: 0.417033  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 88.4% / 0.430740\n",
            "\t\tValidación: 88.2% / 0.428003 \n",
            "\n",
            "Iteración 6/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.408472  [    0/48000]\n",
            "\tPérdida: 0.393954  [10000/48000]\n",
            "\tPérdida: 0.422037  [20000/48000]\n",
            "\tPérdida: 0.373496  [30000/48000]\n",
            "\tPérdida: 0.392132  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 89.0% / 0.398932\n",
            "\t\tValidación: 88.7% / 0.404030 \n",
            "\n",
            "Iteración 7/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.443444  [    0/48000]\n",
            "\tPérdida: 0.378507  [10000/48000]\n",
            "\tPérdida: 0.356626  [20000/48000]\n",
            "\tPérdida: 0.390746  [30000/48000]\n",
            "\tPérdida: 0.370010  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 89.5% / 0.377601\n",
            "\t\tValidación: 88.8% / 0.386546 \n",
            "\n",
            "Iteración 8/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.375413  [    0/48000]\n",
            "\tPérdida: 0.346228  [10000/48000]\n",
            "\tPérdida: 0.350961  [20000/48000]\n",
            "\tPérdida: 0.390044  [30000/48000]\n",
            "\tPérdida: 0.312726  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 89.9% / 0.362329\n",
            "\t\tValidación: 89.4% / 0.372622 \n",
            "\n",
            "Iteración 9/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.317438  [    0/48000]\n",
            "\tPérdida: 0.357240  [10000/48000]\n",
            "\tPérdida: 0.333987  [20000/48000]\n",
            "\tPérdida: 0.334158  [30000/48000]\n",
            "\tPérdida: 0.357564  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 90.1% / 0.350827\n",
            "\t\tValidación: 89.7% / 0.362075 \n",
            "\n",
            "Iteración 10/10\n",
            "-------------------------------\n",
            "\tPérdida: 0.383717  [    0/48000]\n",
            "\tPérdida: 0.299595  [10000/48000]\n",
            "\tPérdida: 0.329352  [20000/48000]\n",
            "\tPérdida: 0.323484  [30000/48000]\n",
            "\tPérdida: 0.370188  [40000/48000]\n",
            "\tExactitud/pérdida promedio:\n",
            "\t\tEntrenamiento: 90.4% / 0.341462\n",
            "\t\tValidación: 89.9% / 0.353772 \n",
            "\n",
            "Listo, el modelo ha sido entrenado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Perfecto! En este punto ya hemos entrenado y validado nuestro modelo.\n",
        "\n",
        "Podemos ver que en la iteración 10 se tiene una exactitud de casi el 90% con ambos sets (entrenamiento y validación). Así que podemos decir que nuestro modelo esta generando buenas predicciones y que no tiene *overfitting*.\n",
        "\n",
        "Sólo nos resta tomar el modelo entrenado y generar predicciones. Veamos cómo hacerlo."
      ],
      "metadata": {
        "id": "tpDxKxj8PrPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Generando predicciones con el modelo entrenado\n",
        "\n",
        "Habiendo entrenado el modelo ya podemos comenzar a usarlo para generar predicciones.\n",
        "\n",
        "Estas predicciones implican que debemos introducir una imagen y el modelo debe predecir la categoría a la que pertenece.\n",
        "\n",
        "Para ello crearemos una sencilla función (`predecir`) con estas características:\n",
        "\n",
        "- Entradas: el modelo entrenado y una imagen\n",
        "- Salida: mostrará en pantalla la imagen original y la categoría predicha\n",
        "\n",
        "Veamos cómo crear esta función:"
      ],
      "metadata": {
        "id": "iTwsL-8OP6ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predecir(model, img):\n",
        "    # Generar predicción\n",
        "    logits = model(img)\n",
        "    y_pred = logits.argmax(1).item()\n",
        "\n",
        "    # Mostrar imagen original y categoría predicha\n",
        "    plt.imshow(img.cpu().squeeze(), cmap=\"gray\")\n",
        "    plt.title(f'Categoría predicha: {y_pred}');"
      ],
      "metadata": {
        "id": "kkhxv426NZ-R"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y pongamos a prueba esta función. Acá la idea es usar imágenes que nunca haya \"visto\" el modelo, es decir por ejemplo imágenes del set de prueba:"
      ],
      "metadata": {
        "id": "T7ialA92QzQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomar una imagen del set de prueba\n",
        "img, lbl = test[1235]\n",
        "\n",
        "# Y generar la predicción\n",
        "predecir(modelo, img)"
      ],
      "metadata": {
        "id": "0sUhLca1cpT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "6b6e7d6c-4035-4cee-fb1e-8cde94298b4c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAG0CAYAAAB0cfPUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJtZJREFUeJzt3X9YlXWe//HXQeFgCIcI+eUPBDV1M23HUSLzR8oIlq6/puzHtcFsq5nolTnZjs0aWl3DZLONM2ZOzbY67abOWOOvai3FxC3RRs1cbTJBSk3ApOGAKGjw+f7h17MeAfXgwQ/g83Fdn+vi3Pfnc5/3+Xh7XtznvrmPwxhjBADANRZguwAAwPWJAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEXMa///u/69VXX7VdBtDqEEDAJXzwwQeaOnWqevbsabsUv1i2bJkcDoe++uorz7Jhw4Zp2LBhPm3nq6++ksPh0K9+9Sv/FojrCgGEBhUUFOjRRx9VYmKigoODFRYWpkGDBuk3v/mNTp8+7fP2XnnlFS1btsz/hTaRyspKTZkyRfPnz/f5DRpN6+TJk8rKylJaWpoiIiLkcDha1L6Fc9raLgDN07vvvqt7771XTqdTDz/8sPr06aMzZ87oo48+0uzZs7V//3699tprPm3zlVdeUWRkpDIyMpqmaD97+umn1bt3bz399NO2S2lSH3zwge0SfHbixAk9++yz6tKli/r166ctW7bYLgmNQAChjsLCQt1///2Kj4/X5s2bFRsb61mXmZmp/Px8vfvuuxYrbFqVlZUKCQnRb37zG9uleHz//feqra1VUFCQ37fdFNtsarGxsSoqKlJMTIx27typAQMG2C4JjcBHcKhjwYIFOnnypF5//XWv8Dmve/fuevzxxz2Ply5dquHDhysqKkpOp1N/93d/pyVLlniN6dq1q/bv36/c3Fw5HA45HA6vj7XKyso0c+ZMde7cWU6nU927d9cLL7yg2tpar+2UlpbqH//xHxUWFqbw8HClp6frs88+q/cjmM2bN2vw4MEKCQlReHi4xo4dq7/+9a9efebNmyeHw6HPP/9cDz74oG688UbdeeedXusudCWvtSEZGRlq3769Dh06pNTUVIWEhCguLk7PPvusLrwp/YXnVxYuXKhu3brJ6XTq888/lyR98cUX+vGPf6yIiAgFBwfrhz/8odatW1fn+fbv36/hw4erXbt26tSpk55//vk68ynVfw6oqqpK8+bN080336zg4GDFxsZqwoQJKigoqDP+tdde89Q4YMAA/eUvf/Fav3fvXmVkZHg+yo2JidE//dM/qbS0tM62vvjiCx0+fPiyc+l0OhUTE3PZfmjeOAJCHevXr1diYqLuuOOOK+q/ZMkS3XLLLfqHf/gHtW3bVuvXr9e0adNUW1urzMxMSdLChQs1Y8YMtW/fXj//+c8lSdHR0ZKkU6dOaejQofrmm2/06KOPqkuXLtq2bZvmzJmjoqIiLVy4UJJUW1urMWPG6JNPPtFjjz2mXr16ae3atUpPT69T06ZNmzRq1CglJiZq3rx5On36tBYtWqRBgwZp9+7d6tq1q1f/e++9Vz169NAvfvELXeobSq7ktV5KTU2N0tLSdPvtt2vBggXasGGDsrKy9P333+vZZ5/16rt06VJVVVVpypQpcjqdioiI0P79+zVo0CB17NhRP/vZzxQSEqI//elPGjdunN5++22NHz9eklRcXKy77rpL33//vaffa6+9pnbt2l1RjaNHj1ZOTo7uv/9+Pf7446qoqNDGjRu1b98+devWzdN3+fLlqqio0KOPPiqHw6EFCxZowoQJOnTokAIDAyVJGzdu1KFDh/STn/xEMTExno9v9+/fr+3bt3uFfO/evTV06FA+UrteGOACbrfbSDJjx4694jGnTp2qsyw1NdUkJiZ6LbvlllvM0KFD6/R97rnnTEhIiPnyyy+9lv/sZz8zbdq0MYcPHzbGGPP2228bSWbhwoWePjU1NWb48OFGklm6dKln+W233WaioqJMaWmpZ9lnn31mAgICzMMPP+xZlpWVZSSZBx54oE5d59c15rXWJz093UgyM2bM8Cyrra0199xzjwkKCjLffvutMcaYwsJCI8mEhYWZ48ePe21jxIgR5tZbbzVVVVVe27jjjjtMjx49PMtmzpxpJJkdO3Z4lh0/fty4XC4jyRQWFnqWDx061Ovf5T/+4z+MJPPSSy/VeQ21tbVeNd50003mu+++86xfu3atkWTWr1/vWVbfnK1YscJIMlu3bvVaLqnefeRS/vKXv9T590fLwEdw8FJeXi5JCg0NveIxF/5W7Xa7deLECQ0dOlSHDh2S2+2+7PhVq1Zp8ODBuvHGG3XixAlPS0lJUU1NjbZu3SpJ2rBhgwIDAzV58mTP2ICAgDpHHkVFRdqzZ48yMjIUERHhWd63b1/96Ec/0nvvvVenhqlTp16T1ypJ06dP9/zscDg0ffp0nTlzRps2bfLqN3HiRHXo0MHz+LvvvtPmzZt13333qaKiwjNPpaWlSk1N1cGDB/XNN99Ikt577z3dfvvtGjhwoGd8hw4d9NBDD122vrfffluRkZGaMWNGnXUXfyQ5adIk3XjjjZ7HgwcPliQdOnTIs+zCOauqqtKJEyd0++23S5J2797ttT1jDEc/1xE+goOXsLAwSVJFRcUVj/n444+VlZWlvLw8nTp1ymud2+2Wy+W65PiDBw9q7969Xm+2Fzp+/Lgk6euvv1ZsbKxuuOEGr/Xdu3f3evz1119LUr1/u9O7d2+9//77ngsNzktISLhkjedd7WsNCAhQYmKi17Kbb75Zkrz+Nqe+mvLz82WM0dy5czV37tx6t3/8+HF17NhRX3/9tZKSkuqsv5K/ZyooKFDPnj3Vtu3l3x66dOni9fh8GP3tb3/zLPvuu+80f/58rVy50vNved6VhjZaJwIIXsLCwhQXF6d9+/ZdUf+CggKNGDFCvXr10ksvvaTOnTsrKChI7733nn7961/Xe9L7YrW1tfrRj36kp556qt7159+gm9KVnBvxx2u9mprOb//JJ59UampqvWMuDuOm1qZNm3qXmwvOo913333atm2bZs+erdtuu03t27dXbW2t0tLS/D5naFkIINQxevRovfbaa8rLy1NycvIl+65fv17V1dVat26d12/DH374YZ2+F398c163bt108uRJpaSkXPK54uPj9eGHH+rUqVNeR0H5+fl1+knSgQMH6mzjiy++UGRkpNfRz5Xy5bU2pLa2VocOHfIK1S+//FKS6lwYcbHzR06BgYFXNFcHDx6ss7y+OblYt27dtGPHDp09e9ZzIUFj/e1vf1NOTo7mz5+vZ555xrO8vtpw/eEcEOp46qmnFBISon/+539WSUlJnfUFBQWev5E5/xvwhb/xut1uLV26tM64kJAQlZWV1Vl+3333KS8vT++//36ddWVlZfr+++8lSampqTp79qx+//vfe9bX1tZq8eLFXmNiY2N122236Q9/+IPX8+3bt08ffPCB7r777ku8+ob58lov5eWXX/b8bIzRyy+/rMDAQI0YMeKS46KiojRs2DC9+uqrKioqqrP+22+/9fx89913a/v27frkk0+81r/55puXrW/ixIk6ceKEV50X1uuL+uZMkufKxotd6WXYaB04AkId3bp10/LlyzVp0iT17t3b604I27Zt06pVqzx3Mxg5cqSCgoI0ZswYPfroozp58qR+//vfKyoqqs6bZP/+/bVkyRI9//zz6t69u6KiojR8+HDNnj1b69at0+jRo5WRkaH+/fursrJS//u//6u33npLX331lSIjIzVu3DgNHDhQP/3pT5Wfn69evXpp3bp1+u677yR5H2G9+OKLGjVqlJKTk/XII494LsN2uVyaN29eo+bFl9fakODgYG3YsEHp6elKSkrSf//3f+vdd9/V008/3eA5sAstXrxYd955p2699VZNnjxZiYmJKikpUV5eno4eParPPvtM0rlfIv7zP/9TaWlpevzxxz2XYcfHx2vv3r2XfI6HH35Yb7zxhmbNmqVPPvlEgwcPVmVlpTZt2qRp06Zp7NixV/RapXMf6Q4ZMkQLFizQ2bNn1bFjR33wwQcqLCyst78vl2G//PLLKisr07FjxySdO0I9evSoJGnGjBmXPR+HZsDeBXho7r788kszefJk07VrVxMUFGRCQ0PNoEGDzKJFi7wuA163bp3p27evCQ4ONl27djUvvPCC51LeCy/3LS4uNvfcc48JDQ2tc7ltRUWFmTNnjunevbsJCgoykZGR5o477jC/+tWvzJkzZzz9vv32W/Pggw+a0NBQ43K5TEZGhvn444+NJLNy5Uqv+jdt2mQGDRpk2rVrZ8LCwsyYMWPM559/7tXn/KXW5y+Brm/dha70tdYnPT3dhISEmIKCAjNy5Ehzww03mOjoaJOVlWVqamo8/c5f4vziiy/Wu52CggLz8MMPm5iYGBMYGGg6duxoRo8ebd566y2vfnv37jVDhw41wcHBpmPHjua5554zr7/++mUvwzbm3KXTP//5z01CQoIJDAw0MTEx5sc//rEpKCi4bI2STFZWlufx0aNHzfjx4014eLhxuVzm3nvvNceOHavT7/zYK70MOz4+3kiqt13u3wLNg8MYH4+pgWZmzZo1Gj9+vD766CMNGjTIdjkNysjI0FtvvaWTJ0/aLgVoFjgHhBbl4rtw19TUaNGiRQoLC9MPfvADS1UBaAzOAaFFmTFjhk6fPq3k5GRVV1frz3/+s7Zt26Zf/OIXV3QpNYDmgwBCizJ8+HD927/9m9555x1VVVWpe/fuWrRokdfdBQC0DJwDAgBYwTkgAIAVBBAAwAoCCABgRbO7CKG2tlbHjh1TaGhog/cOAwA0X8YYVVRUKC4uTgEBDR/nNLsAOnbsmDp37my7DADAVTpy5Ig6derU4Ppm9xGcL1+EBgBovi73ft5kAbR48WJ17dpVwcHBSkpK8ror76XwsRsAtA6Xez9vkgD64x//qFmzZikrK0u7d+9Wv379lJqaWufbEAEA17GmuMPpwIEDTWZmpudxTU2NiYuLM9nZ2Zcd63a7G7zDLY1Go9FaTnO73Zd8v/f7EdCZM2e0a9cur29sDAgIUEpKivLy8ur0r66uVnl5uVcDALR+fg+gEydOqKamRtHR0V7Lo6OjVVxcXKd/dna2XC6Xp3EFHABcH6xfBTdnzhy53W5PO3LkiO2SAADXgN//DigyMlJt2rRRSUmJ1/KSkhLFxMTU6e90OuV0Ov1dBgCgmfP7EVBQUJD69++vnJwcz7La2lrl5OQoOTnZ308HAGihmuROCLNmzVJ6erp++MMfauDAgVq4cKEqKyv1k5/8pCmeDgDQAjVJAE2aNEnffvutnnnmGRUXF+u2227Thg0b6lyYAAC4fjW7L6QrLy+Xy+WyXQYA4Cq53W6FhYU1uN76VXAAgOsTAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBVtbRcAXI8WLVrk85hp06b5PGb48OE+j5Gk3NzcRo0DfMEREADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYwc1Igas0dOhQn8dMmjTJ5zHGGJ/HzJ071+cxEjcjxbXBERAAwAoCCABghd8DaN68eXI4HF6tV69e/n4aAEAL1yTngG655RZt2rTp/56kLaeaAADemiQZ2rZtq5iYmKbYNACglWiSc0AHDx5UXFycEhMT9dBDD+nw4cMN9q2urlZ5eblXAwC0fn4PoKSkJC1btkwbNmzQkiVLVFhYqMGDB6uioqLe/tnZ2XK5XJ7WuXNnf5cEAGiGHKYxf1zgg7KyMsXHx+ull17SI488Umd9dXW1qqurPY/Ly8sJIbQojfk7oFWrVvk8JiIiwucxW7Zs8XmMJKWkpDRqHHAht9utsLCwBtc3+dUB4eHhuvnmm5Wfn1/veqfTKafT2dRlAACamSb/O6CTJ0+qoKBAsbGxTf1UAIAWxO8B9OSTTyo3N1dfffWVtm3bpvHjx6tNmzZ64IEH/P1UAIAWzO8fwR09elQPPPCASktL1aFDB915553avn27OnTo4O+nAgC0YH4PoJUrV/p7k0CzNm3aNJ/HNOaCgsbo0aPHNXkeoDG4FxwAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgRVvbBQAtncPhuCZjGuNaPQ/QGBwBAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAV3IwUuErGmGsypjGu1fMAjcEREADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArfA6grVu3asyYMYqLi5PD4dCaNWu81htj9Mwzzyg2Nlbt2rVTSkqKDh486K96AQCthM8BVFlZqX79+mnx4sX1rl+wYIF++9vf6ne/+5127NihkJAQpaamqqqq6qqLBQC0Hj5/I+qoUaM0atSoetcZY7Rw4UL967/+q8aOHStJeuONNxQdHa01a9bo/vvvv7pqAQCthl/PARUWFqq4uFgpKSmeZS6XS0lJScrLy6t3THV1tcrLy70aAKD182sAFRcXS5Kio6O9lkdHR3vWXSw7O1sul8vTOnfu7M+SAADNlPWr4ObMmSO32+1pR44csV0SAOAa8GsAxcTESJJKSkq8lpeUlHjWXczpdCosLMyrAQBaP78GUEJCgmJiYpSTk+NZVl5erh07dig5OdmfTwUAaOF8vgru5MmTys/P9zwuLCzUnj17FBERoS5dumjmzJl6/vnn1aNHDyUkJGju3LmKi4vTuHHj/Fk3AKCF8zmAdu7cqbvuusvzeNasWZKk9PR0LVu2TE899ZQqKys1ZcoUlZWV6c4779SGDRsUHBzsv6oBAC2ewxhjbBdxofLycrlcLttl4DoVGhrq85jc3Fyfx/Tt29fnMY3xzTffNGpcfHy8nyvB9cjtdl/yvL71q+AAANcnAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArPD56xiA1iw8PNznMf369fN/IX6ycOFC2yUADeIICABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCs4GakwFUyxtguAWiROAICAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACu4GSnQiq1cudJ2CUCDOAICAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACu4GSnQihUVFdkuAWgQR0AAACsIIACAFT4H0NatWzVmzBjFxcXJ4XBozZo1XuszMjLkcDi8Wlpamr/qBQC0Ej4HUGVlpfr166fFixc32CctLU1FRUWetmLFiqsqEgDQ+vh8EcKoUaM0atSoS/ZxOp2KiYlpdFEAgNavSc4BbdmyRVFRUerZs6cee+wxlZaWNti3urpa5eXlXg0A0Pr5PYDS0tL0xhtvKCcnRy+88IJyc3M1atQo1dTU1Ns/OztbLpfL0zp37uzvkgAAzZDDGGMaPdjh0OrVqzVu3LgG+xw6dEjdunXTpk2bNGLEiDrrq6urVV1d7XlcXl5OCMGaxux7hYWFTVCJf7Rty5/6wR63262wsLAG1zf5ZdiJiYmKjIxUfn5+veudTqfCwsK8GgCg9WvyADp69KhKS0sVGxvb1E8FAGhBfD4+P3nypNfRTGFhofbs2aOIiAhFRERo/vz5mjhxomJiYlRQUKCnnnpK3bt3V2pqql8LBwC0bD4H0M6dO3XXXXd5Hs+aNUuSlJ6eriVLlmjv3r36wx/+oLKyMsXFxWnkyJF67rnn5HQ6/Vc1AKDF8zmAhg0bpktdt/D+++9fVUGATUOHDvV5jMPhaIJKgNaPe8EBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACr6vF7jA3Xff7fOYq/hWe+C6xhEQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFjBzUiBC0yaNMnnMdfqZqQrVqy4Js8DXCscAQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFdyMFK3S5MmTbZfgd8XFxbZLAPyKIyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIKbkaJVat++faPGBQT4/jtZbW1to57LV//zP/9zTZ4HuFY4AgIAWEEAAQCs8CmAsrOzNWDAAIWGhioqKkrjxo3TgQMHvPpUVVUpMzNTN910k9q3b6+JEyeqpKTEr0UDAFo+nwIoNzdXmZmZ2r59uzZu3KizZ89q5MiRqqys9PR54okntH79eq1atUq5ubk6duyYJkyY4PfCAQAtm08XIWzYsMHr8bJlyxQVFaVdu3ZpyJAhcrvdev3117V8+XINHz5ckrR06VL17t1b27dv1+233+6/ygEALdpVnQNyu92SpIiICEnSrl27dPbsWaWkpHj69OrVS126dFFeXl6926iurlZ5eblXAwC0fo0OoNraWs2cOVODBg1Snz59JJ37zvqgoCCFh4d79Y2Ojm7w++yzs7Plcrk8rXPnzo0tCQDQgjQ6gDIzM7Vv3z6tXLnyqgqYM2eO3G63px05cuSqtgcAaBka9Yeo06dP1zvvvKOtW7eqU6dOnuUxMTE6c+aMysrKvI6CSkpKFBMTU++2nE6nnE5nY8oAALRgPh0BGWM0ffp0rV69Wps3b1ZCQoLX+v79+yswMFA5OTmeZQcOHNDhw4eVnJzsn4oBAK2CT0dAmZmZWr58udauXavQ0FDPeR2Xy6V27drJ5XLpkUce0axZsxQREaGwsDDNmDFDycnJXAEHAPDiUwAtWbJEkjRs2DCv5UuXLlVGRoYk6de//rUCAgI0ceJEVVdXKzU1Va+88opfigUAtB4+BZAx5rJ9goODtXjxYi1evLjRRQG2NObGolfy/8Ifdu/efU2eB7hWuBccAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGjUN6ICzd2kSZNsl3BJR48e9XnM6dOnm6ASwB6OgAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACm5GimZv9OjRPo/5+7//+yaoxH+2b9/u85jS0tImqASwhyMgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALDCYYwxtou4UHl5uVwul+0yAABXye12KywsrMH1HAEBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsMKnAMrOztaAAQMUGhqqqKgojRs3TgcOHPDqM2zYMDkcDq82depUvxYNAGj5fAqg3NxcZWZmavv27dq4caPOnj2rkSNHqrKy0qvf5MmTVVRU5GkLFizwa9EAgJavrS+dN2zY4PV42bJlioqK0q5duzRkyBDP8htuuEExMTH+qRAA0Cpd1Tkgt9stSYqIiPBa/uabbyoyMlJ9+vTRnDlzdOrUqQa3UV1drfLycq8GALgOmEaqqakx99xzjxk0aJDX8ldffdVs2LDB7N271/zXf/2X6dixoxk/fnyD28nKyjKSaDQajdbKmtvtvmSONDqApk6dauLj482RI0cu2S8nJ8dIMvn5+fWur6qqMm6329OOHDlifdJoNBqNdvXtcgHk0zmg86ZPn6533nlHW7duVadOnS7ZNykpSZKUn5+vbt261VnvdDrldDobUwYAoAXzKYCMMZoxY4ZWr16tLVu2KCEh4bJj9uzZI0mKjY1tVIEAgNbJpwDKzMzU8uXLtXbtWoWGhqq4uFiS5HK51K5dOxUUFGj58uW6++67ddNNN2nv3r164oknNGTIEPXt27dJXgAAoIXy5byPGvicb+nSpcYYYw4fPmyGDBliIiIijNPpNN27dzezZ8++7OeAF3K73dY/t6TRaDTa1bfLvfc7/n+wNBvl5eVyuVy2ywAAXCW3262wsLAG13MvOACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFc0ugIwxtksAAPjB5d7Pm10AVVRU2C4BAOAHl3s/d5hmdshRW1urY8eOKTQ0VA6Hw2tdeXm5OnfurCNHjigsLMxShfYxD+cwD+cwD+cwD+c0h3kwxqiiokJxcXEKCGj4OKftNazpigQEBKhTp06X7BMWFnZd72DnMQ/nMA/nMA/nMA/n2J4Hl8t12T7N7iM4AMD1gQACAFjRogLI6XQqKytLTqfTdilWMQ/nMA/nMA/nMA/ntKR5aHYXIQAArg8t6ggIANB6EEAAACsIIACAFQQQAMCKFhNAixcvVteuXRUcHKykpCR98skntku65ubNmyeHw+HVevXqZbusJrd161aNGTNGcXFxcjgcWrNmjdd6Y4yeeeYZxcbGql27dkpJSdHBgwftFNuELjcPGRkZdfaPtLQ0O8U2kezsbA0YMEChoaGKiorSuHHjdODAAa8+VVVVyszM1E033aT27dtr4sSJKikpsVRx07iSeRg2bFid/WHq1KmWKq5fiwigP/7xj5o1a5aysrK0e/du9evXT6mpqTp+/Ljt0q65W265RUVFRZ720Ucf2S6pyVVWVqpfv35avHhxvesXLFig3/72t/rd736nHTt2KCQkRKmpqaqqqrrGlTaty82DJKWlpXntHytWrLiGFTa93NxcZWZmavv27dq4caPOnj2rkSNHqrKy0tPniSee0Pr167Vq1Srl5ubq2LFjmjBhgsWq/e9K5kGSJk+e7LU/LFiwwFLFDTAtwMCBA01mZqbncU1NjYmLizPZ2dkWq7r2srKyTL9+/WyXYZUks3r1as/j2tpaExMTY1588UXPsrKyMuN0Os2KFSssVHhtXDwPxhiTnp5uxo4da6UeW44fP24kmdzcXGPMuX/7wMBAs2rVKk+fv/71r0aSycvLs1Vmk7t4HowxZujQoebxxx+3V9QVaPZHQGfOnNGuXbuUkpLiWRYQEKCUlBTl5eVZrMyOgwcPKi4uTomJiXrooYd0+PBh2yVZVVhYqOLiYq/9w+VyKSkp6brcP7Zs2aKoqCj17NlTjz32mEpLS22X1KTcbrckKSIiQpK0a9cunT171mt/6NWrl7p06dKq94eL5+G8N998U5GRkerTp4/mzJmjU6dO2SivQc3uZqQXO3HihGpqahQdHe21PDo6Wl988YWlquxISkrSsmXL1LNnTxUVFWn+/PkaPHiw9u3bp9DQUNvlWVFcXCxJ9e4f59ddL9LS0jRhwgQlJCSooKBATz/9tEaNGqW8vDy1adPGdnl+V1tbq5kzZ2rQoEHq06ePpHP7Q1BQkMLDw736tub9ob55kKQHH3xQ8fHxiouL0969e/Uv//IvOnDggP785z9brNZbsw8g/J9Ro0Z5fu7bt6+SkpIUHx+vP/3pT3rkkUcsVobm4P777/f8fOutt6pv377q1q2btmzZohEjRlisrGlkZmZq375918V50EtpaB6mTJni+fnWW29VbGysRowYoYKCAnXr1u1al1mvZv8RXGRkpNq0aVPnKpaSkhLFxMRYqqp5CA8P180336z8/HzbpVhzfh9g/6grMTFRkZGRrXL/mD59ut555x19+OGHXl/fEhMTozNnzqisrMyrf2vdHxqah/okJSVJUrPaH5p9AAUFBal///7KycnxLKutrVVOTo6Sk5MtVmbfyZMnVVBQoNjYWNulWJOQkKCYmBiv/aO8vFw7duy47vePo0ePqrS0tFXtH8YYTZ8+XatXr9bmzZuVkJDgtb5///4KDAz02h8OHDigw4cPt6r94XLzUJ89e/ZIUvPaH2xfBXElVq5caZxOp1m2bJn5/PPPzZQpU0x4eLgpLi62Xdo19dOf/tRs2bLFFBYWmo8//tikpKSYyMhIc/z4cdulNamKigrz6aefmk8//dRIMi+99JL59NNPzddff22MMeaXv/ylCQ8PN2vXrjV79+41Y8eONQkJCeb06dOWK/evS81DRUWFefLJJ01eXp4pLCw0mzZtMj/4wQ9Mjx49TFVVle3S/eaxxx4zLpfLbNmyxRQVFXnaqVOnPH2mTp1qunTpYjZv3mx27txpkpOTTXJyssWq/e9y85Cfn2+effZZs3PnTlNYWGjWrl1rEhMTzZAhQyxX7q1FBJAxxixatMh06dLFBAUFmYEDB5rt27fbLumamzRpkomNjTVBQUGmY8eOZtKkSSY/P992WU3uww8/NJLqtPT0dGPMuUux586da6Kjo43T6TQjRowwBw4csFt0E7jUPJw6dcqMHDnSdOjQwQQGBpr4+HgzefLkVvdLWn2vX5JZunSpp8/p06fNtGnTzI033mhuuOEGM378eFNUVGSv6CZwuXk4fPiwGTJkiImIiDBOp9N0797dzJ4927jdbruFX4SvYwAAWNHszwEBAFonAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFjx/wB6FMUBlFLbigAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Y listo, ya tenemos nuestro clasificador de imágenes creado, entrenado, validad y puesto a prueba!"
      ],
      "metadata": {
        "id": "-kyU9AuuRETo"
      }
    }
  ]
}